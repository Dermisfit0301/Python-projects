{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fraud transaction detection**\n",
        "\n",
        "We are trying to create an algorithm that detects a fraud transaction. Fraud transaction is the one that is not made by the user and is made by a phisher who has obtained the credentials by using sneaky methods. We have been provided with a dataset obtained from a bank.\n",
        "\n",
        "We are going to be studying the historical data in order to find patterns that indicate a fraud. Then we will apply machine learning techniques to create a model that will identify a fraud.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y86S-6m4OxLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1:Setting up the environment**\n",
        "\n",
        "*Packages*\n",
        "\n",
        "We will import libraries from python server which will help us with the analysis. statsmodels is a Python module that provides classes and functions for the estimation of many different statistical models\n",
        "\n",
        "Pandas used for data analysis and manipulation\n",
        "\n",
        "*   Numpy for mathematical formulae and stuff like that.\n",
        "\n",
        "*   Seaborn for data visualization\n",
        "\n",
        "*   Matplotlib will help us visualize the data\n",
        "\n",
        "* Scipy for statistical functions\n",
        "\n",
        "* Sklearn package will help us with Machine learning.\n",
        "\n",
        "*Loading and viewing the dataset*\n",
        "\n",
        "The dataset file will be loaded and we will have a look at the data types."
      ],
      "metadata": {
        "id": "GhZ21-a_jkEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#importing packages\n",
        "from pandas import Series;  from numpy.random import randn\n",
        "from statsmodels.stats.weightstats import ttest_ind\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import ttest_ind\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import shapiro\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression as lgr\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing as preproc\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, auc, balanced_accuracy_score, confusion_matrix, f1_score, precision_score, average_precision_score, roc_auc_score,  recall_score,  precision_recall_curve as skm\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest, RandomForestClassifier \n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, train_test_split \n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
        "from hyperopt import hp, tpe, STATUS_OK, fmin, Trials \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "S9u58kOyyYbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import Counter\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "aY6RvAahyYic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#getting the dataset\n",
        "fraud=pd.read_csv(\"/content/Fraud.csv\")\n",
        "fraud.head()"
      ],
      "metadata": {
        "id": "jPC0JIjDyYlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing the datatypes\n",
        "fraud.dtypes"
      ],
      "metadata": {
        "id": "-CF9UOSMyYpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#seeing the shape\n",
        "fraud.shape"
      ],
      "metadata": {
        "id": "a6xrLw9vyYrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data cleaning and organizing**\n",
        "\n",
        "In this step, we are going to be \"cleaning\" the data. We are going to remove the unnecessary columns and deal with missing values. We will also remove outliers in the dataset and make the data fit for analysis."
      ],
      "metadata": {
        "id": "2sp0x2M9jkHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing null values\n",
        "fraud.isnull().sum()"
      ],
      "metadata": {
        "id": "Qgv5rk3s-YRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting median values of numerical variables \n",
        "med_amt=fraud.amount.astype(\"float\").median(axis=0)\n",
        "med_obal=fraud.oldbalanceOrg.astype(\"float\").median(axis=0)\n",
        "med_nbal=fraud.newbalanceOrig.astype(\"float\").median(axis=0)\n",
        "med_obd=fraud.oldbalanceDest.astype(\"float\").median(axis=0)\n",
        "med_nbd=fraud.newbalanceDest.astype(\"float\").median(axis=0)\n"
      ],
      "metadata": {
        "id": "VuQ4G_lEG8PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing outliers in amount\n",
        "sb.boxplot(fraud.amount)"
      ],
      "metadata": {
        "id": "7zYs-IL5Kg05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outlier treatment for variable amount\n",
        "fraud.amount.quantile([0.1, 0.25, 0.5, 0.70, 0.9, 0.95, 0.99]).round()"
      ],
      "metadata": {
        "id": "TbrMxBfRKkLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing limits\n",
        "amt_HE=fraud[fraud.amount > 381832].copy()\n"
      ],
      "metadata": {
        "id": "yT3yqN1wKkUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for x in fraud.amount:\n",
        "    if x > 381832:\n",
        "        fraud.amount.replace(x,np.nan,inplace=True)"
      ],
      "metadata": {
        "id": "BQbkl720LlD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if outliers gone \n",
        "sb.boxplot(fraud.amount)"
      ],
      "metadata": {
        "id": "mJamzaMpKka4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing nan values with median \n",
        "fraud.amount.replace(np.nan, med_amt, inplace=True)"
      ],
      "metadata": {
        "id": "2xdaUBqLMVdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing outliers in oldbalanceOrg\n",
        "sb.boxplot(fraud.oldbalanceOrg)"
      ],
      "metadata": {
        "id": "Zsbk7mrNMlVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outlier treatment for variable oldbalanceOrg\n",
        "fraud.oldbalanceOrg.quantile([0.1, 0.25, 0.5, 0.70, 0.9, 0.95, 0.99]).round()"
      ],
      "metadata": {
        "id": "UNUCkp4YMlbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing limits\n",
        "oldbalanceOrg_out_HE=fraud[fraud.oldbalanceOrg> 104351].copy()\n"
      ],
      "metadata": {
        "id": "BCbIP6hfMleT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for x in fraud.oldbalanceOrg:\n",
        "    if x > 104351:\n",
        "        fraud.oldbalanceOrg.replace(x,np.nan,inplace=True)"
      ],
      "metadata": {
        "id": "ebW0LbJtMlg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if outliers gone \n",
        "sb.boxplot(fraud.oldbalanceOrg)"
      ],
      "metadata": {
        "id": "yRGnTEIfMlj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing nan values with median \n",
        "fraud.oldbalanceOrg.replace(np.nan, med_obal, inplace=True)"
      ],
      "metadata": {
        "id": "NxmxyR1kMlms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing outliers in newbalanceOrig\n",
        "sb.boxplot(fraud.newbalanceOrig)\n"
      ],
      "metadata": {
        "id": "elWf8eB7yY39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outlier treatment for variable newbalanceOrig\n",
        "fraud.newbalanceOrig.quantile([0.1, 0.25, 0.5, 0.70, 0.9, 0.95, 0.99]).round()"
      ],
      "metadata": {
        "id": "U0QgdqKWyY1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing limits\n",
        "newbalanceOrig_out_HE=fraud[fraud.newbalanceOrig>  113772].copy()"
      ],
      "metadata": {
        "id": "KJ32EieGyYzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for x in fraud.newbalanceOrig:\n",
        "    if x >  113772:\n",
        "        fraud.newbalanceOrig.replace(x,np.nan,inplace=True)"
      ],
      "metadata": {
        "id": "PjMvWLWmQtJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if outliers gone \n",
        "sb.boxplot(fraud.newbalanceOrig)"
      ],
      "metadata": {
        "id": "YEcllF57yYuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing nan values with median \n",
        "fraud.newbalanceOrig.replace(np.nan, med_nbal, inplace=True)"
      ],
      "metadata": {
        "id": "TajUcCmayYws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing outliers in oldbalanceDest\n",
        "sb.boxplot(fraud.oldbalanceDest)"
      ],
      "metadata": {
        "id": "O7Uc0SgcPvuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outlier treatment for variable oldbalanceDest\n",
        "fraud.oldbalanceDest.quantile([0.1, 0.25, 0.5, 0.70, 0.9, 0.95, 0.99]).round()"
      ],
      "metadata": {
        "id": "FqjpKPiCPvx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing limits\n",
        "fraud.oldbalanceDest_out_HE=fraud[fraud.oldbalanceDest> 650350].copy()"
      ],
      "metadata": {
        "id": "4p3WA1MdPv0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for x in fraud.oldbalanceDest:\n",
        "    if x > 650350:\n",
        "        fraud.oldbalanceDest.replace(x,np.nan,inplace=True)"
      ],
      "metadata": {
        "id": "2zVGtHp5Pv27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing nan values with median \n",
        "fraud.oldbalanceDest.replace(np.nan, med_obd, inplace=True)"
      ],
      "metadata": {
        "id": "PZtdDhozPv5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if outliers gone \n",
        "sb.boxplot(fraud.oldbalanceDest)"
      ],
      "metadata": {
        "id": "QFfFyaP5Pv7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing outliers in newbalanceDest\n",
        "sb.boxplot(fraud.newbalanceDest)"
      ],
      "metadata": {
        "id": "uZEeqF5NPv-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outlier treatment for variable newbalanceDest\n",
        "fraud.newbalanceDest.quantile([0.1, 0.25, 0.5, 0.70, 0.9, 0.95, 0.99]).round()"
      ],
      "metadata": {
        "id": "N9t_gGYaPwBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for x in fraud.newbalanceDest:\n",
        "    if x > 877978:\n",
        "        fraud.newbalanceDest.replace(x,np.nan,inplace=True)"
      ],
      "metadata": {
        "id": "2bC84w8QPwC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if outliers gone \n",
        "sb.boxplot(fraud.newbalanceDest)"
      ],
      "metadata": {
        "id": "MryGx7zsSQUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing nan values with median \n",
        "fraud.newbalanceDest.replace(np.nan, med_nbd, inplace=True)"
      ],
      "metadata": {
        "id": "bVMO0nWjSQM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Exploratory Data analysis**\n",
        "\n",
        "Here we are going to know about our data. We will run hypothesis tests in this segment. We will use graphics and statistics to understand the data."
      ],
      "metadata": {
        "id": "9uu1miEWjkMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking how accurately frauds are flagged before\n",
        "real_fraud= sum(fraud.isFraud==1)\n",
        "identify_real_fraud= sum(fraud.isFlaggedFraud==1)\n",
        "accuracy=identify_real_fraud/(identify_real_fraud+real_fraud)*100\n",
        "print(\"The accuracy of identifying a fraud is\",accuracy)\n"
      ],
      "metadata": {
        "id": "OAFDaXNY_IQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing correlation\n",
        "corr=fraud.corr()\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "sb.heatmap(corr,annot=True)"
      ],
      "metadata": {
        "id": "vAL8S1DKazUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeing legit and fraud\n",
        "plt.figure(figsize=(15,30))\n",
        "labels = [\"Normal\", \"Fraud\"]\n",
        "count_classes = fraud.value_counts(fraud['isFraud'], sort= True)\n",
        "count_classes.plot(kind = \"bar\", rot = 4)\n",
        "plt.title(\"Seeing fraud and Normal\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(range(2), labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "azVMOdD0azXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights gained**\n",
        "\n",
        "\n",
        "\n",
        "1.   Around 1% or less than that are fraud transactions.\n",
        "\n",
        "2.   The amount is having a moderately negative correlation with new balance and having moderate positive correlation with oldbalancedest and newbalancedest.\n",
        "\n",
        "3. Our test showed that the bank is unable to flag frauds even if they are frauds. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cFXvP1WcjLYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Data Processing**\n",
        "\n",
        "Here we are going to modify the variables in the dataset so as to facilitate better analysis."
      ],
      "metadata": {
        "id": "CCveHSEsjkQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting a new dataset\n",
        "fraud1=fraud.copy()\n",
        "fraud1.head()"
      ],
      "metadata": {
        "id": "oywCOf2rof-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting list of object type columns\n",
        "\n",
        "obs = fraud1.select_dtypes(include = \"object\").columns\n",
        "print (obs)"
      ],
      "metadata": {
        "id": "wwFbEmTKnuvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doing label encoding\n",
        "for feature in obs:\n",
        "    fraud1[feature] = le.fit_transform(fraud1[feature].astype(str))\n",
        "\n",
        "print (fraud1.info())"
      ],
      "metadata": {
        "id": "Ik20ZOvppF1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping columns (inter correlated ones and unnecessary)\n",
        "fraud1 = fraud1.drop(['oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest','step','nameOrig','nameDest'],axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "rApGqofLpF73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Model building**\n",
        "\n",
        "We will use ml techniques to build and select the appropriate model."
      ],
      "metadata": {
        "id": "9znt0haJsMFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Scaling\n",
        "scaler = StandardScaler()\n",
        "fraud1[\"NormalizedAmount\"] = scaler.fit_transform(fraud1[\"amount\"].values.reshape(-1, 1))\n",
        "fraud1.drop([\"amount\"], inplace= True, axis= 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "-aF2EQz_sbp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining X and y\n",
        "Y = fraud1[\"isFraud\"]\n",
        "X = fraud1.drop([\"isFraud\"], axis= 1)"
      ],
      "metadata": {
        "id": "jjRaTkOopF-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size= 0.25, random_state= 42)\n",
        "\n",
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)"
      ],
      "metadata": {
        "id": "vgRkGh0ipGBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud1"
      ],
      "metadata": {
        "id": "-1x0EhOmuB0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First Model:Decision Tree \n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred_dt = decision_tree.predict(X_test)\n",
        "decision_tree_score = decision_tree.score(X_test, Y_test) * 100"
      ],
      "metadata": {
        "id": "2PX6mBZRazfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Model:RANDOM FOREST\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators= 42)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred_rf = random_forest.predict(X_test)\n",
        "random_forest_score = random_forest.score(X_test, Y_test) * 100"
      ],
      "metadata": {
        "id": "OQqYjk5Zazcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification Model 1\n",
        "\n",
        "classification_report_dt = classification_report(Y_test, Y_pred_dt)\n",
        "print(\"Classification Report - Decision Tree\")\n",
        "print(classification_report_dt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DDFt2zhgxZOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# classification report Model 2\n",
        "\n",
        "classification_report_rf = classification_report(Y_test, Y_pred_rf)\n",
        "print(\"Classification Report - Random Forest\")\n",
        "print(classification_report_rf)"
      ],
      "metadata": {
        "id": "_euW4ueYxZQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC ROC for Model 1\n",
        "\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(Y_test, Y_pred_dt)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('ROC - DT')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "DwBwnexXzhLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC ROC - RF for Model 2\n",
        "\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(Y_test, Y_pred_rf)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('ROC - RF')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vxYxeyTbzrHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which model to use?**\n",
        "\n",
        "The first and second models are same accuracy wise but precision plays an important role here hence I choose the second one. Random forest is a better choice as we only want to catch wrong transactions rather than correct ones. "
      ],
      "metadata": {
        "id": "_HtM0-RXx8jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final words**\n",
        "\n",
        "\n",
        "*What are the key factors that predict fraudulent customer?*\n",
        "\n",
        "1.is source of request legitimate?\n",
        "\n",
        "2.valid organization\n",
        "\n",
        "3.vendors transaction history\n",
        "\n",
        "\n",
        "*What kind of prevention should be adopted while company update its infrastructure? *\n",
        "\n",
        "1.Use smart vertified apps only.\n",
        "\n",
        "2.Browse through secured websites.\n",
        "\n",
        "3.Using secure internet\n",
        "\n",
        "4.Keep device security updated\n",
        "\n",
        "5.Reporting any suspicious activity to bank\n",
        "\n",
        "*Assuming these actions have been implemented, how would you determine if they work?*\n",
        "\n",
        "1.More websites rating your bank for safety.\n",
        "\n",
        "2.Customers not sending complaints.\n",
        "\n",
        "3.Lowering budget for customer grievance.\n"
      ],
      "metadata": {
        "id": "c_AycYKJjL3D"
      }
    }
  ]
}